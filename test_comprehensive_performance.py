#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»¼åˆæ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•æ‰€æœ‰ä¼˜åŒ–åŠŸèƒ½çš„æ•ˆæœ
"""

import time
import requests
import json
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime

class ComprehensivePerformanceTester:
    def __init__(self, base_url="http://127.0.0.1:5000"):
        self.base_url = base_url
        self.session = requests.Session()
        self.results = {}
        
    def test_page_load_performance(self):
        """æµ‹è¯•é¡µé¢åŠ è½½æ€§èƒ½"""
        print("=== æµ‹è¯•é¡µé¢åŠ è½½æ€§èƒ½ ===")
        
        endpoints = [
            "/",
            "/orders",
            "/orders/statistics",
            "/admin/wechat-users"
        ]
        
        results = {}
        for endpoint in endpoints:
            times = []
            for i in range(5):  # æ¯ä¸ªé¡µé¢æµ‹è¯•5æ¬¡
                start_time = time.time()
                try:
                    response = self.session.get(f"{self.base_url}{endpoint}")
                    load_time = time.time() - start_time
                    times.append(load_time)
                    print(f"  {endpoint}: {load_time:.3f}s (çŠ¶æ€ç : {response.status_code})")
                except Exception as e:
                    print(f"  {endpoint}: é”™è¯¯ - {e}")
                    times.append(None)
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            valid_times = [t for t in times if t is not None]
            if valid_times:
                results[endpoint] = {
                    'avg_time': sum(valid_times) / len(valid_times),
                    'min_time': min(valid_times),
                    'max_time': max(valid_times),
                    'success_rate': len(valid_times) / len(times)
                }
        
        self.results['page_load'] = results
        return results
    
    def test_api_performance(self):
        """æµ‹è¯•APIæ€§èƒ½"""
        print("\n=== æµ‹è¯•APIæ€§èƒ½ ===")
        
        api_endpoints = [
            "/api/orders",
            "/api/statistics",
            "/api/cache/stats"
        ]
        
        results = {}
        for endpoint in api_endpoints:
            times = []
            for i in range(10):  # æ¯ä¸ªAPIæµ‹è¯•10æ¬¡
                start_time = time.time()
                try:
                    response = self.session.get(f"{self.base_url}{endpoint}")
                    api_time = time.time() - start_time
                    times.append(api_time)
                    print(f"  {endpoint}: {api_time:.3f}s (çŠ¶æ€ç : {response.status_code})")
                except Exception as e:
                    print(f"  {endpoint}: é”™è¯¯ - {e}")
                    times.append(None)
            
            valid_times = [t for t in times if t is not None]
            if valid_times:
                results[endpoint] = {
                    'avg_time': sum(valid_times) / len(valid_times),
                    'min_time': min(valid_times),
                    'max_time': max(valid_times),
                    'success_rate': len(valid_times) / len(times)
                }
        
        self.results['api_performance'] = results
        return results
    
    def test_cache_effectiveness(self):
        """æµ‹è¯•ç¼“å­˜æ•ˆæœ"""
        print("\n=== æµ‹è¯•ç¼“å­˜æ•ˆæœ ===")
        
        # æµ‹è¯•è®¢å•åˆ—è¡¨é¡µé¢çš„ç¼“å­˜æ•ˆæœ
        endpoint = "/orders"
        times_without_cache = []
        times_with_cache = []
        
        # ç¬¬ä¸€æ¬¡è®¿é—®ï¼ˆæ— ç¼“å­˜ï¼‰
        for i in range(3):
            start_time = time.time()
            response = self.session.get(f"{self.base_url}{endpoint}")
            load_time = time.time() - start_time
            times_without_cache.append(load_time)
            print(f"  æ— ç¼“å­˜è®¿é—® {i+1}: {load_time:.3f}s")
        
        # ç­‰å¾…ä¸€ä¸‹è®©ç¼“å­˜ç”Ÿæ•ˆ
        time.sleep(2)
        
        # ç¬¬äºŒæ¬¡è®¿é—®ï¼ˆæœ‰ç¼“å­˜ï¼‰
        for i in range(3):
            start_time = time.time()
            response = self.session.get(f"{self.base_url}{endpoint}")
            load_time = time.time() - start_time
            times_with_cache.append(load_time)
            print(f"  æœ‰ç¼“å­˜è®¿é—® {i+1}: {load_time:.3f}s")
        
        avg_without_cache = sum(times_without_cache) / len(times_without_cache)
        avg_with_cache = sum(times_with_cache) / len(times_with_cache)
        
        improvement = ((avg_without_cache - avg_with_cache) / avg_without_cache) * 100
        
        results = {
            'avg_without_cache': avg_without_cache,
            'avg_with_cache': avg_with_cache,
            'improvement_percent': improvement,
            'times_without_cache': times_without_cache,
            'times_with_cache': times_with_cache
        }
        
        self.results['cache_effectiveness'] = results
        print(f"  ç¼“å­˜æ•ˆæœ: å¹³å‡æå‡ {improvement:.1f}%")
        return results
    
    def test_concurrent_requests(self):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚æ€§èƒ½"""
        print("\n=== æµ‹è¯•å¹¶å‘è¯·æ±‚æ€§èƒ½ ===")
        
        def make_request(endpoint):
            start_time = time.time()
            try:
                response = self.session.get(f"{self.base_url}{endpoint}")
                duration = time.time() - start_time
                return {
                    'endpoint': endpoint,
                    'duration': duration,
                    'status_code': response.status_code,
                    'success': True
                }
            except Exception as e:
                duration = time.time() - start_time
                return {
                    'endpoint': endpoint,
                    'duration': duration,
                    'error': str(e),
                    'success': False
                }
        
        endpoints = ["/orders", "/api/orders", "/orders/statistics"]
        concurrent_levels = [5, 10, 20]
        
        results = {}
        for level in concurrent_levels:
            print(f"  æµ‹è¯• {level} ä¸ªå¹¶å‘è¯·æ±‚...")
            
            all_results = []
            with ThreadPoolExecutor(max_workers=level) as executor:
                # ä¸ºæ¯ä¸ªå¹¶å‘çº§åˆ«åˆ›å»ºå¤šä¸ªè¯·æ±‚
                futures = []
                for _ in range(level):
                    for endpoint in endpoints:
                        futures.append(executor.submit(make_request, endpoint))
                
                for future in as_completed(futures):
                    all_results.append(future.result())
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            successful_requests = [r for r in all_results if r['success']]
            failed_requests = [r for r in all_results if not r['success']]
            
            if successful_requests:
                durations = [r['duration'] for r in successful_requests]
                results[level] = {
                    'total_requests': len(all_results),
                    'successful_requests': len(successful_requests),
                    'failed_requests': len(failed_requests),
                    'success_rate': len(successful_requests) / len(all_results),
                    'avg_duration': sum(durations) / len(durations),
                    'min_duration': min(durations),
                    'max_duration': max(durations)
                }
                
                print(f"    {level}å¹¶å‘: æˆåŠŸç‡ {results[level]['success_rate']:.1%}, "
                      f"å¹³å‡æ—¶é—´ {results[level]['avg_duration']:.3f}s")
        
        self.results['concurrent_performance'] = results
        return results
    
    def test_image_optimization(self):
        """æµ‹è¯•å›¾ç‰‡ä¼˜åŒ–åŠŸèƒ½"""
        print("\n=== æµ‹è¯•å›¾ç‰‡ä¼˜åŒ–åŠŸèƒ½ ===")
        
        # æµ‹è¯•å›¾ç‰‡ä¼˜åŒ–API
        test_images = [
            "test.jpg",
            "sample.png"
        ]
        
        optimization_params = [
            {'width': 100, 'height': 100},
            {'width': 300, 'height': 300},
            {'quality': 50},
            {'quality': 90}
        ]
        
        results = {}
        for image in test_images:
            results[image] = {}
            for params in optimization_params:
                param_str = '&'.join([f"{k}={v}" for k, v in params.items()])
                url = f"{self.base_url}/optimized-image/{image}?{param_str}"
                
                start_time = time.time()
                try:
                    response = self.session.get(url)
                    duration = time.time() - start_time
                    
                    results[image][param_str] = {
                        'duration': duration,
                        'status_code': response.status_code,
                        'content_length': len(response.content) if response.status_code == 200 else 0
                    }
                    
                    print(f"  {image} ({param_str}): {duration:.3f}s, "
                          f"çŠ¶æ€ç : {response.status_code}")
                    
                except Exception as e:
                    results[image][param_str] = {
                        'duration': time.time() - start_time,
                        'error': str(e)
                    }
                    print(f"  {image} ({param_str}): é”™è¯¯ - {e}")
        
        self.results['image_optimization'] = results
        return results
    
    def test_database_query_performance(self):
        """æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½"""
        print("\n=== æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½ ===")
        
        # æµ‹è¯•ä¸åŒçš„æŸ¥è¯¢å‚æ•°
        test_cases = [
            {'page': 1, 'per_page': 10},
            {'page': 1, 'per_page': 20},
            {'page': 2, 'per_page': 10},
            {'start_date': '2025-07-01', 'end_date': '2025-07-31'},
            {'search_type': 'wechat_name', 'search_value': 'test'}
        ]
        
        results = {}
        for i, params in enumerate(test_cases):
            param_str = '&'.join([f"{k}={v}" for k, v in params.items()])
            url = f"{self.base_url}/api/orders?{param_str}"
            
            times = []
            for j in range(5):  # æ¯ä¸ªæŸ¥è¯¢æµ‹è¯•5æ¬¡
                start_time = time.time()
                try:
                    response = self.session.get(url)
                    query_time = time.time() - start_time
                    times.append(query_time)
                except Exception as e:
                    times.append(None)
            
            valid_times = [t for t in times if t is not None]
            if valid_times:
                results[f"case_{i+1}"] = {
                    'params': params,
                    'avg_time': sum(valid_times) / len(valid_times),
                    'min_time': min(valid_times),
                    'max_time': max(valid_times),
                    'success_rate': len(valid_times) / len(times)
                }
                
                print(f"  æŸ¥è¯¢ {i+1} ({param_str}): å¹³å‡ {results[f'case_{i+1}']['avg_time']:.3f}s")
        
        self.results['database_performance'] = results
        return results
    
    def generate_report(self):
        """ç”Ÿæˆç»¼åˆæ€§èƒ½æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ç»¼åˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š")
        print("="*60)
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'base_url': self.base_url,
            'results': self.results
        }
        
        # é¡µé¢åŠ è½½æ€§èƒ½æ€»ç»“
        if 'page_load' in self.results:
            print("\nğŸ“Š é¡µé¢åŠ è½½æ€§èƒ½:")
            for endpoint, data in self.results['page_load'].items():
                print(f"  {endpoint}: å¹³å‡ {data['avg_time']:.3f}s, "
                      f"æˆåŠŸç‡ {data['success_rate']:.1%}")
        
        # APIæ€§èƒ½æ€»ç»“
        if 'api_performance' in self.results:
            print("\nğŸ”Œ APIæ€§èƒ½:")
            for endpoint, data in self.results['api_performance'].items():
                print(f"  {endpoint}: å¹³å‡ {data['avg_time']:.3f}s, "
                      f"æˆåŠŸç‡ {data['success_rate']:.1%}")
        
        # ç¼“å­˜æ•ˆæœæ€»ç»“
        if 'cache_effectiveness' in self.results:
            data = self.results['cache_effectiveness']
            print(f"\nğŸ’¾ ç¼“å­˜æ•ˆæœ: å¹³å‡æå‡ {data['improvement_percent']:.1f}%")
        
        # å¹¶å‘æ€§èƒ½æ€»ç»“
        if 'concurrent_performance' in self.results:
            print("\nâš¡ å¹¶å‘æ€§èƒ½:")
            for level, data in self.results['concurrent_performance'].items():
                print(f"  {level}å¹¶å‘: æˆåŠŸç‡ {data['success_rate']:.1%}, "
                      f"å¹³å‡æ—¶é—´ {data['avg_duration']:.3f}s")
        
        # æ•°æ®åº“æ€§èƒ½æ€»ç»“
        if 'database_performance' in self.results:
            print("\nğŸ—„ï¸ æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½:")
            for case, data in self.results['database_performance'].items():
                print(f"  {case}: å¹³å‡ {data['avg_time']:.3f}s, "
                      f"æˆåŠŸç‡ {data['success_rate']:.1%}")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        with open('comprehensive_performance_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: comprehensive_performance_report.json")
        
        return report

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç»¼åˆæ€§èƒ½æµ‹è¯•...")
    
    tester = ComprehensivePerformanceTester()
    
    try:
        # æ‰§è¡Œå„é¡¹æµ‹è¯•
        tester.test_page_load_performance()
        tester.test_api_performance()
        tester.test_cache_effectiveness()
        tester.test_concurrent_requests()
        tester.test_image_optimization()
        tester.test_database_query_performance()
        
        # ç”ŸæˆæŠ¥å‘Š
        tester.generate_report()
        
        print("\nâœ… ç»¼åˆæ€§èƒ½æµ‹è¯•å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main() 